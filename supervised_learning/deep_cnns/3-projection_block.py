#!/usr/bin/env python3
"""
aaa
"""

from tensorflow import keras as K


def projection_block(A_prev, filters, s=2):
    """
    Construye un bloque residual con proyecci√≥n (shortcut convolucional).

    Par√°metros:
    - A_prev: Tensor de entrada (salida de la capa anterior)
    - filters: tupla de 3 enteros (F11, F3, F12) que indican:
        * F11: filtros de la primera conv 1x1 (reducci√≥n de canales)
        * F3:  filtros de la conv central 3x3
        * F12: filtros de la √∫ltima conv 1x1 (restauraci√≥n de canales)
        y tambi√©n de la shortcut
    - s: stride que se aplica en la primera convoluci√≥n y en la shortcut

    Proceso:
    - Ruta principal: conv1x1 ‚Üí BN ‚Üí ReLU ‚Üí conv3x3 ‚Üí BN ‚Üí ReLU ‚Üí conv1x1 ‚Üí BN
    - Shortcut: conv1x1 con stride s ‚Üí BN
    - Suma ambas rutas ‚Üí ReLU

    Retorna:
    - Activaci√≥n final (ReLU) luego de la suma.
    """

    # Asignamos los filtros
    F11, F3, F12 = filters

    # Inicializador HeNormal con semilla 0 (ideal para ReLU)
    he_init = K.initializers.HeNormal(seed=0)

    # ============================
    # üõ£Ô∏è Ruta Principal (Main Path)
    # ============================

    # Primera convoluci√≥n 1x1 con stride s (puede reducir resoluci√≥n)
    X = K.layers.Conv2D(filters=F11, kernel_size=1, strides=s, padding='same',
                        kernel_initializer=he_init)(A_prev)
    X = K.layers.BatchNormalization(axis=3)(X)  # Normalizamos por canales
    X = K.layers.Activation('relu')(X)

    # Segunda convoluci√≥n 3x3 (stride=1, mantiene tama√±o)
    X = K.layers.Conv2D(filters=F3, kernel_size=3, strides=1, padding='same',
                        kernel_initializer=he_init)(X)
    X = K.layers.BatchNormalization(axis=3)(X)
    X = K.layers.Activation('relu')(X)

    # Tercera convoluci√≥n 1x1 (para expandir a F12 canales)
    X = K.layers.Conv2D(filters=F12, kernel_size=1, strides=1, padding='same',
                        kernel_initializer=he_init)(X)
    X = K.layers.BatchNormalization(axis=3)(X)

    # ===============================
    # üîÅ Ruta Shortcut (con proyecci√≥n)
    # ===============================

    shortcut = K.layers.Conv2D(
        filters=F12, kernel_size=1, strides=s, padding='same',
        kernel_initializer=he_init
        )(A_prev)
    shortcut = K.layers.BatchNormalization(axis=3)(shortcut)

    # ================================
    # ‚ûï Suma de las rutas y activaci√≥n
    # ================================

    X = K.layers.Add()([X, shortcut])  # Sumamos las dos rutas
    X = K.layers.Activation('relu')(X)  # Activaci√≥n final

    return X
